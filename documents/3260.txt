Peak detection of measured signal
algorithm language-agnostic
We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.
This works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.
My initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?

We do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code. 


You could try signal averaging, i.e. for each point, average the value with the surrounding 3 or more points. If the noise blips are huge, then even this may not help.
I realise that this was language agnostic, but guessing that you are using LabView, there are lots of pre-packaged signal processing VIs that come with LabView that you can use to do smoothing and noise reduction. The NI forums are a great place to get more specialised help on this sort of thing.
You could apply some Standard Devision to your logic and take notice of peaks over x%.
I think you want to cross-correlate your signal with an expected, exemplar signal. But, it has been such a long time since I studied signal processing and even then I didn't take much notice.
I don't know very much about instrumentation, so this might be totally impractical, but then again it might be a helpful different direction.  If you know how the readings can fail, and there is a certain interval between peaks given such failures, why not do gradient descent at each interval.  If the descent brings you back to an area you've searched before, you can abandon it.  Depending upon the shape of the sampled surface, this also might help you find peaks faster than search.
This problem has been studied in some detail. 
There are a set of very up-to-date implementations in the TSpectrum* classes of ROOT (a nuclear/particle physics analysis tool). The code works in one- to three-dimensional data.
The ROOT source code is available, so you can grab this implementation if you want.
From the TSpectrum class documentation:
The algorithms used in this class have been published in the following references:

[1] M.Morhac et al.: Background
  elimination methods for
  multidimensional coincidence gamma-ray
  spectra. Nuclear Instruments and
  Methods in Physics Research A 401
  (1997) 113-
  132.
[2]  M.Morhac et al.: Efficient one- and two-dimensional Gold
  deconvolution and its application to
  gamma-ray spectra decomposition.
  Nuclear Instruments and Methods in
  Physics Research A 401 (1997) 385-408.
[3]  M.Morhac et al.: Identification of peaks in
  multidimensional coincidence gamma-ray
  spectra. Nuclear Instruments and
  Methods in Research Physics A 
  443(2000), 108-125.

The papers are linked from the class documentation for those of you who don't have a NIM online subscription.

The short version of what is done is that the histogram flattened to eliminate noise, and then local maxima are detected by brute force in the flattened histogram. 

This method is basically from David Marr's  book "Vision"
Gaussian blur your signal with the expected width of your peaks.
this gets rid of noise spikes and your phase data is undamaged.
Then edge detect (LOG will do)
Then your edges were the edges of features (like peaks).
look between edges  for peaks, sort peaks by size, and you're done.
I have used variations on this and they work very well.

Is there a qualitative difference between the desired peak and the unwanted second peak? If both peaks are "sharp" -- i.e. short in time duration -- when looking at the signal in the frequency domain (by doing FFT) you'll get energy at most bands. But if the "good" peak reliably has energy present at frequencies not existing in the "bad" peak, or vice versa, you may be able to automatically differentiate them that way.

There are lots and lots of classic peak detection methods, any of which might work.  You'll have to see what, in particular, bounds the quality of your data.  Here are basic descriptions:

Between any two points in your data, (x(0),y(0)) and (x(n),y(n)), add up y(i+1)-y(i) for 0 <= i < n and call this T ("travel") and set R ("rise") to y(n)- y(0) + k for suitably small k.  T/R > 1 indicates a peak.  This works OK if large travel due to noise is unlikely or if noise distributes symmetrically around a base curve shape.  For your application, accept the earliest peak with a score above a given threshold, or analyze the curve of travel per rise values for more interesting properties.
Use matched filters to score similarity to a standard peak shape (essentially, use a normalized dot-product against some shape to get a cosine-metric of similarity)
Deconvolve against a standard peak shape and check for high values (though I often find 2 to be less sensitive to noise for simple instrumentation output).
Smooth the data and check for triplets of equally spaced points where, if x0 < x1 < x2, y1 > 0.5*(y0+y2), or check Euclidean distances like this:  D((x0,y0),(x1,y1)) + D((x1,y1),(x2,y2)) > D((x0,y0),(x2,y2)), which relies on the triangle inequality.  Using simple ratios will again provide you a scoring mechanism.
Fit a very simple 2-gaussian mixture model to your data (for example, Numerical Recipes has a nice ready-made chunk of code).  Take the earlier peak.  This will deal correctly with overlapping peaks.
Find the best match in the data to a simple Gaussian, Cauchy, Poisson, or what-have-you curve.  Evaluate this curve over a broad range and subtract it from a copy of the data after noting it's peak location.  Repeat.  Take the earliest peak whose model parameters (standard deviation probably, but some applications might care about kurtosis or other features) meet some criterion.  Watch out for artifacts left behind when peaks are subtracted from the data.
Best match might be determined by the kind of match scoring suggested in #2 above.

I've done what you're doing before:  finding peaks in DNA sequence data, finding peaks in derivatives estimated from measured curves, and finding peaks in histograms.
I encourage you to attend carefully to proper baselining.  Wiener filtering or other filtering or simple histogram analysis is often an easy way to baseline in the presence of noise.
Finally, if your data is typically noisy and you're getting data off the card as unreferenced single-ended output (or even referenced, just not differential), and if you're averaging lots of observations into each data point, try sorting those observations and throwing away the first and last quartile and averaging what remains.  There are a host of such outlier elimination tactics that can be really useful.

I would like to contribute to this thread an algorithm that I have developed myself:
This algorithm signals when the data points are a specified number of standard deviations away from the moving mean. However, when a signal is detected, subsequent data points that are also a signal (so significantly away from the moving mean), will not corrupt the signal threshold. That is, the algorithm creates a  'new mean' and 'new st.dev.' in which the data points that are signals are not used. Therefore, the threshold remains uncorrupted and is able to correctly identify future signals too, without loss of performance. This works extremely well!
In order to display the power of this robust algorithm, I have prepared a demo in which the user can specify its own data. This little demo displays both how the algorithm works and why it is so useful. 

The full working Matlab code for this demo:
function [] = RobustDetectionDemo()

%% SPECIFICATIONS
LAG         = 10;       % lag for the moving mean and moving st. dev.
DIFF        = 3.5;      % number of st. dev. from the mean to signal
INFLUENCE   = 0.0;      % when signal: how much is mean/st.dev. influenced?
                            % or e.g. 0.05/0.1 for influencing
DIRECTION   = 'both';   % signal when 'up'/'down'/'both' from the mean

%%
figure(1);
subplot(2,2,1);
title('Draw 30 data points');
ylim([0 5]); xlim([0 50]);
[x,y] = ginputExtra_realtime(30, true, LAG, DIFF, INFLUENCE, DIRECTION);
end

function [x y] = ginputExtra_realtime(n,booText, LAG, DIFF, INFLUENCE, DIRECTION)
if booText == true
    bText = booText;
else
    bText = false;
end
H = gca;
set(H, 'YLimMode', 'manual'); set(H, 'XLimMode', 'manual');
set(H, 'YLim', get(H,'YLim')); set(H, 'XLim', get(H,'XLim'));
numPoints = n; xg = []; yg = [];
for i=1:numPoints
    [xi yi] = ginput(1);
    xg = [xg xi]; yg = [yg yi];
    if i == 1
        hold on;
        plot(H, xg(i),yg(i),'ro');
        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end
    else
        plot(xg([i-1:i]),yg([i-1:i]),'r');
        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end
        if length(xg) > LAG
            robustMA(xg, yg, LAG, DIFF, INFLUENCE, DIRECTION);
        end
    end    
end
hold off;
x = xg; y = yg;
end

function [] = robustMA( x, y, lag, diff, influence, direction)

% robustMA  :: Signal detection algorithm ::
% Author: Jean-Paul van Brakel

% ************************************************************ %
% TO BE USED FOR: *determining significant and sudden changes*
% ************************************************************ %

% x     = x-axis data
% y     = y-axis data
% lag   = lag of moving mean and moving st.dev.
% diff  = number of st.dev. away from the mean in order to give a signal
% influence = number between 0 and 1 that indicates influence of signals
% direction = 'up'/'down'/'both' which means the following:
%               - 'up'  : only signal for deviations ABOVE the mean
%               - 'down': only signal for deviations BELOW the mean
%               - 'both': signal for deviations ABOVE and BELOW the mean

p = y;
outputmean  = tsmovavg(y,'s',lag,2);
outputstdev = movingstd(y,lag,'backward');

newMean  = zeros(1, length(outputmean));
newStdev = zeros(1, length(outputmean));
signals  = ones(1, length(outputmean));

newMean(lag-1)  = outputmean(lag);
newStdev(lag-1) = outputstdev(lag);

for i = lag:length(outputmean)
   if strcmp(direction, 'up')
       if (p(i) > newMean(i-1)+diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   elseif strcmp(direction, 'down')
       if (p(i) < newMean(i-1)-diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   elseif strcmp(direction, 'both')
       if (p(i) > newMean(i-1)+diff*newStdev(i-1) || ...
           p(i) < newMean(i-1)-diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   end
end

figure(1);
subplot(2,2,2);
hold on;
title('Algorithm output');
area(x, newMean+diff*newStdev, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');
area(x, newMean, 'FaceColor', [1 1 1], 'EdgeColor', 'none');
area(x, newMean, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');
area(x, newMean-diff*newStdev, 'FaceColor', [1 1 1], 'EdgeColor', 'none');
plot(x, p, ':r', 'LineWidth', 1, 'Color', 'black');
plot(x, newMean, 'LineWidth', 2, 'Color', 'red');
plot(x, newMean+newStdev, 'LineWidth', 2, 'Color', 'green');
plot(x, newMean-newStdev, 'LineWidth', 2, 'Color', 'green');
xlim([0 50]);   ylim([0 5])
hold off;
subplot(2,2,4);
hold on;
title('Signal output');
stairs(x, signals, 'LineWidth', 2, 'Color', 'blue');
ylim([0 3]);    xlim([0 50]);
hold off;

end

function s = movingstd(x,k,windowmode)
% movingstd: efficient windowed standard deviation of a time series
% usage: s = movingstd(x,k,windowmode)
%
% Movingstd uses filter to compute the standard deviation, using
% the trick of std = sqrt((sum(x.^2) - n*xbar.^2)/(n-1)).
% Beware that this formula can suffer from numerical problems for
% data which is large in magnitude.

% check for a windowmode
if (nargin<3) || isempty(windowmode)
  % supply the default: 
  windowmode = 'central';
elseif ~ischar(windowmode)
  error 'If supplied, windowmode must be a character flag.'
end
% check for a valid shortening.
valid = {'central' 'forward' 'backward'};
windowmode = lower(windowmode);
ind = strmatch(windowmode,valid);
if isempty(ind)
  error 'Windowmode must be a character flag: ''c'', ''b'', or ''f''.'
else
  windowmode = valid{ind};
end

% length of the time series
n = length(x);

% check for valid k
if (nargin<2) || isempty(k) || (rem(k,1)~=0)
  error 'k was not provided or not an integer.'
end
switch windowmode
  case 'central'
    if k<1
      error 'k must be at least 1 for windowmode = ''central''.'
    end
    if n<(2*k+1)
      error 'k is too large for this short of a series and this windowmode.'
    end
  otherwise
    if k<2
      error 'k must be at least 2 for windowmode = ''forward'' or ''backward''.'
    end
    if (n<k)
      error 'k is too large for this short of a series.'
    end
end

% Improve the numerical analysis by subtracting off the series mean
% this has no effect on the standard deviation.
x = x - mean(x);

% we will need the squared elements 
x2 = x.^2;

% split into the three windowmode cases for simplicity
A = 1;
switch windowmode
  case 'central'
    B = ones(1,2*k+1);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/(2*k+1)))/(2*k));
    s(k:(n-k)) = s((2*k):end);
  case 'forward'
    B = ones(1,k);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));
    s(1:(n-k+1)) = s(k:end);
  case 'backward'
    B = ones(1,k);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));
end

% special case the ends as appropriate
switch windowmode
  case 'central'
    % repairs are needed at both ends
    for i = 1:k
      s(i) = std(x(1:(k+i)));
      s(n-k+i) = std(x((n-2*k+i):n));
    end
  case 'forward'
    % the last k elements must be repaired
    for i = (k-1):-1:1
      s(n-i+1) = std(x((n-i+1):n));
    end
  case 'backward'
    % the first k elements must be repaired
    for i = 1:(k-1)
      s(i) = std(x(1:i));
    end
end
end

The necessary parameters are:

LAG: lag for the moving mean and moving st. dev.
DIFF: number of st. dev. away from the mean to generate a signal
INFLUENCE: when there is a signal, how much is mean/st.dev. influenced? (number between 0-1)
DIRECTION: signal when deviation is 'up'/'down'/'both' away from the mean?

As you can see, I used the settings LAG=10; DIFF=3.5; INFLUENCE=0; for this demo. Feel free to fiddle around with these parameters and study the differences in performance of the algorithm. 
