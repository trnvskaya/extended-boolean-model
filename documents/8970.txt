Accessing iSight programatically?
objective-c osx webcam isight
Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well? 


I don't have a Mac here, but there is some Documentation up here:
http://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html
It looks like you have to go through the QuickTime API. There is supposed to be a Sample Project called "MungGrab" which could be worth a look according to this thread.

Aside from ObjC, you can use the PyObjC or RubyCocoa bindings to access it also. If you're not picky about which language, I'd say use Ruby, as PyObjC is horribly badly documented (even the official Apple page on it refers to the old version, not the one that came with OS X Leopard)
Quartz Composer is probably the easiest way to access it, and .quartz files can be embed in applications pretty easily (and the data piped out to ObjC or such)
Also, I suppose there should be an example or two of this in the /Developer/Examples/

There's a command line utility called isightcapture that does more or less what you want to do. You could probably get the code from the developer (his e-mail address is in the readme you get when you download the utility).

You should check out the QTKit Capture documentation.
On Leopard, you can get at all of it over the RubyCocoa bridge:
require 'osx/cocoa'
OSX.require_framework("/System/Library/Frameworks/QTKit.framework")

OSX::QTCaptureDevice.inputDevices.each do |device|
    puts device.localizedDisplayName
end


If you poke around Apple's mailing lists you can find some code to do it in Java as well. Here's a simple example suitable for capturing individual frames, and here's a more complicated one that's fast enough to display live video.

One thing that hasn't been mentioned so far is the IKPictureTaker, which is part of Image Kit.  This will come up with the standard OS provided panel to take pictures though, with all the possible filter functionality etc. included.  I'm not sure if that's what you want.
I suppose you can use it from other languages as well, considering there are things like cocoa bridges but I have no experience with them.
Googling also came up with another question on stackoverflow that seems to address this issue.

From a related question which specifically asked the solution to be pythonic, you should give a try to motmot's camiface library from Andrew Straw. It also works with firewire cameras, but it works also with the isight, which is what you are looking for.
From the tutorial:
import motmot.cam_iface.cam_iface_ctypes as cam_iface
import numpy as np

mode_num = 0
device_num = 0
num_buffers = 32

cam = cam_iface.Camera(device_num,num_buffers,mode_num)
cam.start_camera()
frame = np.asarray(cam.grab_next_frame_blocking())
print 'grabbed frame with shape %s'%(frame.shape,)


Well, if you really hate ObjectiveC, Swift is quite a nice language too.
QTKit is deprecated since X.7, use AV Foundation for modern Swift and ObjectiveC apps on OS X.
https://developer.apple.com/library/mac/technotes/tn2300/_index.html
Specifically, for OS X.7 and newer, image capture is done by enumerating cameras and such using [AVCaptureDevice devices], then creating an AVCaptureSession, setting up streams: [AVCaptureDeviceInput deviceInputWithDevice: ...] and 
  [ addOutput: ...], then finally [ startRunning].
https://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVCaptureSession_Class/
https://developer.apple.com/library/mac/technotes/tn2300/_index.html#//apple_ref/doc/uid/DTS40012852-CH1-MEDIA_CAPTURE_AND_ACCESS_TO_CAMERA
